<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Hands On : ELK</title>

    <!-- Bootstrap -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

		<!-- home made custom CSS -->
    <link href="css/tuto.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>

    <div class="container">

      <div>
        <h1> Hands On : LogStash, ElasticSearch, Kibana, et plus encore </h1>
        <p class="lead">Ce tutoriel détaillera pas à pas : 
					<ul>
						<li>L'installation locale de LogStash, ElasticSearch et Kibana</li>
						<li>Le traitement de fichiers de logs par LogStash</li>
						<li>L'indexation dans ElasticSearch</li>
						<li>Le requêtage via Kibana</li>
						<li>Et pour aller plus loin : l'utilisation d'un broker de messages et d'agents distants, la mise en cluster d'ElasticSearch, des éléments sur le tuning de performances d'ElasticSearch, ...</li>
					</ul>
				</p>
				<div class="alert alert-warning" role="alert">
					Dans le but d'éviter les incidents de démarrage lors de l'atelier, merci de suivre la partie "Pré-requis et installation" avant l'atelier, depuis un ordinateur connecté à Internet !
				</div>
				<div>
					<ul>
						<li><a href="#install">Pré-requis et installation</a></li>
						<li><a href="#logstash">Etape 1 : LogStash</a></li>
						<li><a href="#es">Etape 2 : ElasticSearch</a></li>
						<li><a href="#kibana">Etape 3 : Kibana</a></li>
						<li><a href="#further">Pour aller plus loin...</a>
							<ul>
								<li><a href="#broker">Utilisation d'un agent et d'un broker de messages</a>
								<li><a href="#cluster">Clustering</a>
								<li><a href="#perf">Eléments de performances</a>
							</ul>
						</li>
					</ul>
				</div>
      </div>

      <div>
				<h2 id="install">Pré-requis et installation</h2>
L'utilisation de la machine virtuelle demande au minimum un ordinateur avec un CPU puissant (type Intel Core i5), <strong>8Go de RAM</strong>, et un système d'exploitation (Windows, Mac ou Linux) <strong>64 bits</strong>. Si votre machine ne dispose pas de ce hardware minimum, merci d'installer avant le début de l'atelier les logiciels indiqués plus bas, dans la section <a href="#novm">Sans machine virtuelle</a> plus bas.

					<h3>Utilisation de la machine virtuelle fournie</h3>
					<div class="alert alert-danger" role="alert">
						TODO
					</div>
 
					<h3 id="novm">Sans machine virtuelle</h3>
Pour tous les logiciels qui ne seront pas installés sous forme de package, nous allons placer les binaires dans un même dossier. Tous les chemins seront relatifs à ce dossier, par exemple pour Linux : <code>/home/cvillard/elk</code>. Il y sera fait référence via la variable : <code>$MY_DIR</code>.
							<h4>Java 8</h4>
<p><strong>Linux (Ubuntu)</strong></p>
<p>
Contrôler la version de Java installée : 
<pre>
$ java -version
openjdk version "1.8.0_66-internal"
OpenJDK Runtime Environment (build 1.8.0_66-internal-b17)
OpenJDK 64-Bit Server VM (build 25.66-b17, mixed mode)
</pre>
Si la version est inférieure à 1.8 ou si la commande est inconnue, installer l'openJDK 8 :
<pre>
$ sudo aptitude install openjdk-8-jdk
</pre>
Vérifier que l'installation s'est bien passée en reprenant la commande de vérification.
</p>
<p><strong>Windows</strong></p>
							<div class="alert alert-danger" role="alert">
								TODO
							</div>

							<h4>LogStash</h4>
<p>Nous utiliserons la dernière version de LogStash : 2.1.0. </p>
<p>Télécharger le ZIP ou le TAR.GZ de la version 2.1.0 à cette adresse : <a href="https://www.elastic.co/downloads/logstash">https://www.elastic.co/downloads/logstash</a>.</p>
<p>Décompresser l'archive dans <code>$MY_DIR</code>. </p>
<p>Tester que LogStash se lance bien avec la commande : 
<pre>
$ ${MY_DIR}/logstash-2.1.0/bin/logstash version
logstash 2.1.0
</pre>
</p>

							<h4>ElasticSearch</h4>
<p>Nous utiliserons la dernière version d'ElasticSearch : 2.1.0. </p>
<p>Télécharger le ZIP ou le TAR de la version 2.1.0 à cette adresse : <a href="https://www.elastic.co/downloads/elasticsearch">https://www.elastic.co/downloads/elasticsearch</a>.</p> 
<p>Décompresser l'archive dans <code>$MY_DIR</code>.</p> 
<p>Tester qu'ElasticSearch se lance bien avec la commande : 
<pre>
$ ./elasticsearch-2.1.0/bin/elasticsearch
</pre>
Une fois la trace suivante reçue dans la console (<code>Kirigi</code> étant le nom du noeud, il change à chaque démarrage) : 
<pre>
[2015-11-28 14:03:28,178][INFO ][node                     ] [Kirigi] started
</pre>
Contrôler à l'URL <a href="http://localhost:9200/">http://localhost:9200/</a> qu'il répond :
<pre>
{
  "name" : "Kirigi",
  "cluster_name" : "elasticsearch",
  "version" : {
    "number" : "2.1.0",
    "build_hash" : "72cd1f1a3eee09505e036106146dc1949dc5dc87",
    "build_timestamp" : "2015-11-18T22:40:03Z",
    "build_snapshot" : false,
    "lucene_version" : "5.3.1"
  },
  "tagline" : "You Know, for Search"
}
</pre>
</p>

							<h4>Kibana</h4>
<p>La version de Kibana compatible avec ElasticSearch 2.1.x est la version 4.3.0. </p>
<p>Télécharger la version comaptible avec votre système à l'adresse: <a href="https://www.elastic.co/downloads/kibana">https://www.elastic.co/downloads/kibana</a>. </p>
<p>Décompresser l'archive dans <code>$MY_DIR</code>. </p>
<p>Lancer Kibana avec la commande :
<pre>
$ ./kibana-4.3.0-linux-x64/bin/kibana
</pre>
Une fois la trace suivante obtenue dans la console :
<pre>
  log   [14:11:46.405] [info][listening] Server running at http://0.0.0.0:5601
</pre>
Vérifier que Kibana répond à l'URL <a href="http://localhost:5601/">http://localhost:5601/</a>. On ne va rien configurer pour l'instant, cela fera partie de la suite du tutoriel.
</p>

							<h4>RabbitMQ</h4>
<p>Erlang est nécessaire au fonctionnement de RabbitMQ.
</p>
<p><strong>Windows</strong></p>
<p>
Télécharger le package Erlang pour Windows 64 bits à l'adresse : <a href="http://www.erlang.org/download.html">http://www.erlang.org/download.html</a>.
</p>
<p>Exécuter l'installeur pour Windows en conservant les options par défaut. </p>

<p>Télécharger l'installeur Windows à l'adresse <a href="https://www.rabbitmq.com/download.html">https://www.rabbitmq.com/download.html</a>. 
</p>
<p>Exécuter l'installeur pour Windows en conservant les options par défaut. </p>

<p><strong>Linux</strong></p>

<p>Pour Ubuntu, installer le package fourni dans les dépots, il contient toutes les dépendances nécessaires :
<pre>
$ sudo aptitude install rabbitmq-server
</pre>
L'installation du paquet déclenche le démarrage du serveur. Contrôler cela via la commande :
<pre>
$ sudo rabbitmqctl status
Status of node 'rabbit@claire-i5' ...
[{pid,16510},
 {running_applications,[{rabbit,"RabbitMQ","3.5.4"},
                        {mnesia,"MNESIA  CXC 138 12","4.13"},
                        {os_mon,"CPO  CXC 138 46","2.4"},
                        {xmerl,"XML parser","1.3.8"},
                        {sasl,"SASL  CXC 138 11","2.5"},
                        {stdlib,"ERTS  CXC 138 10","2.5"},
                        {kernel,"ERTS  CXC 138 10","4.0"}]},
 {os,{unix,linux}},
 {erlang_version,"Erlang/OTP 18 [erts-7.0] [source] [64-bit] [smp:4:4] [async-threads:64] [kernel-poll:true]\n"},
 {memory,[{total,42831280},
          {connection_readers,0},
          {connection_writers,0},
          {connection_channels,0},
          {connection_other,2712},
          {queue_procs,2712},
          {queue_slave_procs,0},
          {plugins,0},
          {other_proc,13403656},
          {mnesia,61024},
          {mgmt_db,0},
          {msg_index,46816},
          {other_ets,761048},
          {binary,13248},
          {code,16907095},
          {atom,654217},
          {other_system,10978752}]},
 {alarms,[]},
 {listeners,[{clustering,25672,"::"},{amqp,5672,"::"}]},
 {vm_memory_high_watermark,0.4},
 {vm_memory_limit,3341025280},
 {disk_free_limit,50000000},
 {disk_free,51512127488},
 {file_descriptors,[{total_limit,65436},
                    {total_used,3},
                    {sockets_limit,58890},
                    {sockets_used,1}]},
 {processes,[{limit,1048576},{used,126}]},
 {run_queue,0},
 {uptime,248}]

</pre>
</p>
<p>Pour les autres distributions, se reporter à la <a href="https://www.rabbitmq.com/download.html">documentation de l'outil</a> (peut nécessiter de compiler Erlang).
</p>


							<h4>Générateur de logs</h4>	
							<div class="alert alert-danger" role="alert">
								TODO
							</div>			
      </div>

			<div>
				<h2 id="logstash">Etape 1 : LogStash</h2>
Dans cette étape, nous allons lire un fichier de logs avec LogStash, découper ces logs pour leur ajouter de la sémantique, et les faire écrire dans la sortie standard. 

				<div class="alert alert-danger" role="alert">
					TODO
				</div>
				
      </div>

			<div>
				<h2 id="es">Etape 2 : ElasticSearch</h2>
Dans cette étape, nous allons utiliser le résultat de l'étape précédente pour indexer les logs découpés dans ElasticSearch et les rechercher sommairement via l'API REST d'ElasticSearch. Nous apprendrons également comme configurer sommairement ElasticSearch et comment le monitorer avec quelques plugins courants.

				<div class="alert alert-danger" role="alert">
					TODO
				</div>
				
      </div>

			<div>
				<h2 id="kibana">Etape 3 : Kibana</h2>
Dans cette étape, nous allons voir comment Kibana permet de rechercher facilement dans ElasticSearch, et nous créerons un dashboard.

				<div class="alert alert-danger" role="alert">
					TODO
				</div>

				<div class="alert alert-success" role="alert">Vous voilà arrivés à la fin du tutoriel. Vous pouvez continuer à lire pour aller plus loin...</div>
      </div>



			<div>
				<h2 id="further">Pour aller plus loin...</h2>
Nous avons vu une infrastructure simple d'exploitation de logs. Elle souffre de nombreux points faibles : goulets d'étranglements de performances, vulnérabilité aux pannes, impact sur la charge des machines monitorées... Ces points peuvent être résolus par l'ajout de nouvelles briques et l'utilisation de clusters.
				
				<h3 id="broker">Utilisation d'un agent et d'un broker de messages</h3>

<p>Deux problèmes principaux sont présents dans l'architecture telle que mise en place dans ce tutoriel : le traitement des messages avec Grok peut être très gourmand en CPU, et le fait de pousser directement dans ElasticSearch implique un couplage fort entre les deux briques. 
</p>
<p>Ces deux points peuvent être problématiques en production : La charge induite par LogStash peut perturber les applications supervisées, et toute indisponibilité d'ElasticSearch peut impacter le fonctionnement de l'agent.
</p>
<p>Pour résoudre cela, il est préférable d'installer LogStash sur les machines supervisées avec une configuration minimale, qui ne fait que lire les fichiers de logs, gérer le multiligne si nécessaire, et pousser les messages dans la suite de l'infrastructure, elle située sur des machines dédiées. Le traitement poussé des messages (Grok notamment) sera réalisé par une ou plusieurs autres instances de LogStash (voir le paragraphe "Clustering" plus loin) sur ces machines dédiées, et se chargera de pousser dans ElasticSearch.
</p>
<p>
Pour communiquer entre le LogStash "agent" installé sur les machines clientes et le LogStash "serveur" réalisant les traitements, il faut insérer entre eux deux une brique intermédiaire de "broker de messages". Plusieurs technologies peuvent être utilisées pour cela : Redis, RabbitMQ, Apache Kafka... Chacune de ces solutions ont leurs avantages et leurs inconvénients, à adapter à chaque cas d'usage. RabbitMQ offrant une bonne simplicité de mise en oeuvre et une interface d'administration pratiques dans le cadre de ce tutoriel, c'est ce que nous allons utiliser.
</p>
<div class="alert alert-info" role="alert">Dans le cadre de ce tutoriel, il est possible de démarrer 2 fois LogStash sur votre PC en même temps, en précisant 2 fichiers de configuration différents pour la partie "agent" et la partie "serveur".</div>
</div>
<div class="alert alert-info" role="alert">Voici un extrait de la documentation de RabbitMQ sur les concepts spécifiques à RabbitMQ d'exchange, de queue et de routage dans RabbitMQ : 
				<div class="alert alert-danger" role="alert">
					TODO
				</div>
</div>

<p>
Dans cette partie, vous pouvez donc :
<ol>
<li>Démarrer un serveur RabbitMQ sur votre poste via la commande <code>$MY_DIR/rabbitmq_server-3.5.6/sbin/rabbitmq-server -detached</code> 
</li>
<li>Configurer un exchange, une queue et un routage dans RabbitMQ (voir plus haut l'explication de ces concepts) :
				<div class="alert alert-danger" role="alert">
					TODO
				</div>
</li>
<li>Séparer le fichier <code>logstash.conf</code> en 2 parties. La première jouera le rôle de l'agent, et contiendra la lecture du fichier de logs et la dépose dans RabbitMQ. La seconde jouera le rôle du serveur, et lira les messages depuis RabbitMQ et les déposer dans ElasticSearch comme précédemment.
</li>
<li>Démarrer les 2 instances de LogStash.
</li>
<li>Constater sur les logs arrivent dans ElasticSearch tout comme avant.
</li>
</ol>

L'état de RabbitMQ et des queues qu'il contient peut être consulté sur l'IHM d'administration (notez le <code>s</code> à <code>https</code>) : <a href="https://localhost:15671/">https://localhost:15671/</a>

</p>


				<h3 id="cluster">Clustering</h3>
<p>
Telle qu'elle, l'application n'est pas tolérante aux pannes : si ElasticSearch s'arrête, toute la chaine devient indisponible. Pour un usage en production, la haute disponibilité, la tolérance aux pannes et la montée en charge par du scaling horizontal peuvent être nécessaires.
</p>
<p>
Comme nous l'avons vu, il est très facile de démarrer plusieurs instances de LogStash. Ainsi, il serait très facile d'installer LogStash sur 2 ou plus de machines, avec un fichier de configuration identique leur faisant lire la même file RabbitMQ et déposer dans le même ElasticSearch, pour dupliquer cette partie de l'infrastructure.
</p>
<p>
Réaliser la même chose au niveau d'ElasticSearch n'est guère plus complexe : il suffit de démarrer un second noeud avec le même nom de cluster que le premier et d'indiquer le premier noeud dans la liste des noeuds du cluster pour que le cluster se forme. En gardant la configuration par défaut qui crée 1 réplique de toutes les données et la répartition automatique des données entre les noeuds implémentée dans ElasticSearch, la haute disponibilité est à l'oeuvre...
</p>
<p>
Dans cette partie, vous pouvez donc :
<ol>
<li>Dupliquer le fichier de configuration <code>elasticsearch.yml</code>, et modifier les ports d'écoute pour pouvoir le lancer sur la même machine que le premier noeud.
<div class="alert alert-danger" role="alert">
					TODO
				</div>
</li>
<li>Configurer dans ce même fichier le premier noeud comme autre membre du cluster pour qu'ils se découvrent :
				<div class="alert alert-danger" role="alert">
					TODO
				</div>
</li>
<li>Démarrer ce second noeud avec le nouveau fichier de configuration, et observer le résultat dans l'IHM Head d'ElasticSearch, sur le premier ou le second noeud (les mêmes données sont affichées) : <a href="https://localhost:9200/">https://localhost:9200/</a>
</li>
</ol>
</p>

<div class="alert alert-info" role="alert">Pour éviter les points uniques de défaillance (SPOF, Single Point of Failure) si à l'étape précédente on a mis en place RabbitMQ entre un LogStash agent et un serveur, il faudra également le mettre en cluster. Cela sort du cadre de ce Hands on, mais toute la documentation est disponible <a href="https://www.rabbitmq.com/clustering.html">sur le site du produit</a>.
</div>

				<h3 id="perf">Eléments de performances</h3>
				<div class="alert alert-danger" role="alert">
					TODO
				</div>
<div class="alert alert-success" role="alert">Vous voilà à la toute fin du tutoriel cette fois-ci... Have fun avec ELK ;)</div>

      </div>

    </div><!-- /.container -->

		<footer class="footer" role="contentinfo">
      <div class="container">
        <ul class="footer-links text-center">
					<li><a href="http://www.duchess-france.org/"><img src="images/duchess.jpg" heigth="32px" width="32px" /></a></li>
      		<li>&middot;</li>
					<li><a href="https://twitter.com/leneurone_eu"><img src="images/twitter.png" /></a></li>
      		<li>&middot;</li>
					<li><a href="https://github.com/leneurone/atelier-duchess-elk"><img src="images/github.png" /></a></li>
				</ul>
      </div>
    </footer> <!-- footer -->


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="../../dist/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="../../assets/js/ie10-viewport-bug-workaround.js"></script>
  </body>
</html>
