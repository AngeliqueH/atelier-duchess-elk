<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <!-- The above 3 meta tags *must* come first in the head; any other head content must come *after* these tags -->
    <title>Hands On : ELK</title>

    <!-- Bootstrap -->
    <link href="css/bootstrap.min.css" rel="stylesheet">

		<!-- home made custom CSS -->
    <link href="css/tuto.css" rel="stylesheet">
    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
      <script src="https://oss.maxcdn.com/html5shiv/3.7.2/html5shiv.min.js"></script>
      <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
  </head>
  <body>

    <div class="container">

      <div>
        <h1> Hands On : LogStash, ElasticSearch, Kibana, et plus encore </h1>
        <p class="lead">Ce tutoriel détaillera pas à pas : 
					<ul>
						<li>L'installation locale de LogStash, ElasticSearch et Kibana</li>
						<li>Le traitement de fichiers de logs par LogStash</li>
						<li>L'indexation dans ElasticSearch</li>
						<li>L'exploitation des données via Kibana</li>
						<li>Et pour aller plus loin : l'utilisation d'un broker de messages et d'agents distants, la mise en cluster d'ElasticSearch, ...</li>
					</ul>
				</p>
				<div class="alert alert-warning" role="alert">
					Dans le but d'éviter les incidents de démarrage lors de l'atelier, merci de suivre la partie "Pré-requis et installation" avant l'atelier, depuis un ordinateur connecté à Internet !
				</div>
				<div>
					<ul>
						<li><a href="#install">Pré-requis et installation</a></li>
						<li><a href="#logstash">Étape 1 : LogStash</a></li>
						<li><a href="#es">Étape 2 : ElasticSearch</a></li>
						<li><a href="#kibana">Étape 3 : Kibana</a></li>
						<li><a href="#further">Pour aller plus loin...</a>
							<ul>
								<li><a href="#rspec">Tests unitaires de LogStash</a>
								<li><a href="#broker">Utilisation d'un agent et d'un broker de messages</a>
								<li><a href="#cluster">Clustering</a>
							</ul>
						</li>
					</ul>
				</div>
      </div>

      <div>
				<h2 id="install">Pré-requis et installation</h2>
L'utilisation de la machine virtuelle demande au minimum un ordinateur avec un CPU puissant (type Intel Core i5), <strong>8Go de RAM</strong>, et un système d'exploitation (Windows, Mac ou Linux) <strong>64 bits</strong>. Si votre machine ne dispose pas de ce hardware minimum, merci d'installer avant le début de l'atelier les logiciels indiqués plus bas, dans la section <a href="#novm">Sans machine virtuelle</a> plus bas.

					<h3>Utilisation de la machine virtuelle fournie</h3>
					<div class="alert alert-danger" role="alert">
						TODO
					</div>
 
					<h3 id="novm">Sans machine virtuelle</h3>
Pour tous les logiciels qui ne seront pas installés sous forme de package, nous allons placer les binaires dans un même dossier. Tous les chemins seront relatifs à ce dossier, par exemple pour Linux : <code>/home/cvillard/elk</code>. Il y sera fait référence via la variable : <code>$MY_DIR</code>.
							<h4>Java 8</h4>
<p><strong>Linux (Ubuntu)</strong></p>
<p>
Contrôler la version de Java installée : 
<pre>
$ java -version
openjdk version "1.8.0_66-internal"
OpenJDK Runtime Environment (build 1.8.0_66-internal-b17)
OpenJDK 64-Bit Server VM (build 25.66-b17, mixed mode)
</pre>
Si la version est inférieure à 1.8 ou si la commande est inconnue, installer l'openJDK 8 :
<pre>
$ sudo aptitude install openjdk-8-jdk
</pre>
Vérifier que l'installation s'est bien passée en reprenant la commande de vérification.
</p>
<p><strong>Windows</strong></p>
<p>
Contrôler la version de Java installée : 
<pre>
> java -version
java version "1.8.0_66"
Java(TM) SE Runtime Environment (build 1.8.0_66-b18)
Java HotSpot(TM) Client VM (build 25.66-b18, mixed mode, sharing)
</pre>
Si la version est inférieure à 1.8, télécharger l'installeur pour Windows 64 bits à cette adresse : <a href="http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html">http://www.oracle.com/technetwork/java/javase/downloads/jdk8-downloads-2133151.html</a>. 
</p>
<p>
Lancer l'installation en conservant les options par défaut.
</p>
<p>
Vérifier que l'installation s'est bien passée en reprenant la commande de vérification.
</p>

							<h4>LogStash</h4>
<p>Nous utiliserons la version 2.1.0 de LogStash. </p>
<p>Télécharger le ZIP ou le TAR.GZ de la version 2.1.0 à cette adresse : <a href="https://www.elastic.co/downloads/logstash">https://www.elastic.co/downloads/logstash</a>.</p>
<p>Décompresser l'archive dans <code>$MY_DIR</code>. </p>
<p>Tester que LogStash se lance bien avec la commande : 
<pre>
$ ./logstash-2.1.0/bin/logstash version
logstash 2.1.0
</pre>
</p>

							<h4>ElasticSearch</h4>
<p>Nous utiliserons la version 2.1.0 d'ElasticSearch. </p>
<p>Télécharger le ZIP ou le TAR de la version 2.1.0 à cette adresse : <a href="https://www.elastic.co/downloads/elasticsearch">https://www.elastic.co/downloads/elasticsearch</a>.</p> 
<p>Décompresser l'archive dans <code>$MY_DIR</code>.</p> 
<p>Tester qu'ElasticSearch se lance bien avec la commande : 
<pre>
$ ./elasticsearch-2.1.0/bin/elasticsearch
</pre>
Une fois la trace suivante reçue dans la console (<code>Kirigi</code> étant le nom du nœud, il change à chaque démarrage) : 
<pre>
[2015-11-28 14:03:28,178][INFO ][node                     ] [Kirigi] started
</pre>
Contrôler à l'URL <a href="http://localhost:9200/">http://localhost:9200/</a> qu'il répond :
<pre>
{
  "name" : "Kirigi",
  "cluster_name" : "elasticsearch",
  "version" : {
    "number" : "2.1.0",
    "build_hash" : "72cd1f1a3eee09505e036106146dc1949dc5dc87",
    "build_timestamp" : "2015-11-18T22:40:03Z",
    "build_snapshot" : false,
    "lucene_version" : "5.3.1"
  },
  "tagline" : "You Know, for Search"
}
</pre>
</p>
							<h4>cURL</h4>
<p>
cURL est utile pour soumettre des requêtes à ElasticSearch.
</p>
<p><strong>Linux (Ubuntu)</strong></p>
<p>
<pre>
$ sudo aptitude install curl
</pre>
</p>

<p><strong>Windows</strong></p>
<p>
Télécharger le ZIP à cette adresse : <a href="http://curl.haxx.se/download.html">http://curl.haxx.se/download.html</a>. L'extraire dans un répertoire sur le disque. Il contient directement l'exécutable, sans installation.
</p>


							<h4>Kibana</h4>
<p>La version de Kibana compatible avec ElasticSearch 2.1.x est la version 4.3.0. </p>
<p>Télécharger la version correspondant à votre système à l'adresse: <a href="https://www.elastic.co/downloads/kibana">https://www.elastic.co/downloads/kibana</a>. </p>
<p>Décompresser l'archive dans <code>$MY_DIR</code>. </p>
<p>Lancer Kibana avec la commande :
<pre>
$ ./kibana-4.3.0-linux-x64/bin/kibana
</pre>
Une fois la trace suivante obtenue dans la console :
<pre>
  log   [14:11:46.405] [info][listening] Server running at http://0.0.0.0:5601
</pre>
Vérifier que Kibana répond à l'URL <a href="http://localhost:5601/">http://localhost:5601/</a>. On ne va rien configurer pour l'instant, cela fera partie de la suite du tutoriel.
</p>

							<h4>RabbitMQ</h4>
<p>Erlang est nécessaire au fonctionnement de RabbitMQ.
</p>
<p><strong>Windows</strong></p>
<p>
Télécharger le package Erlang pour Windows 64 bits à l'adresse : <a href="http://www.erlang.org/download.html">http://www.erlang.org/download.html</a>.
</p>
<p>Exécuter l'installeur pour Windows en conservant les options par défaut. </p>

<p>Télécharger l'installeur Windows à l'adresse <a href="https://www.rabbitmq.com/download.html">https://www.rabbitmq.com/download.html</a>. 
</p>
<p>Exécuter l'installeur pour Windows en conservant les options par défaut. </p>

<p><strong>Linux</strong></p>

<p>Pour Ubuntu, installer le package fourni dans les dépots, il contient toutes les dépendances nécessaires :
<pre>
$ sudo aptitude install rabbitmq-server
</pre>
L'installation du paquet déclenche le démarrage du serveur. Contrôler cela via la commande :
<pre>
$ sudo rabbitmqctl status
Status of node 'rabbit@claire-i5' ...
[{pid,16510},
 {running_applications,[{rabbit,"RabbitMQ","3.5.4"},
                        {mnesia,"MNESIA  CXC 138 12","4.13"},
                        {os_mon,"CPO  CXC 138 46","2.4"},
                        {xmerl,"XML parser","1.3.8"},
                        {sasl,"SASL  CXC 138 11","2.5"},
                        {stdlib,"ERTS  CXC 138 10","2.5"},
                        {kernel,"ERTS  CXC 138 10","4.0"}]},
 {os,{unix,linux}},
 {erlang_version,"Erlang/OTP 18 [erts-7.0] [source] [64-bit] [smp:4:4] [async-threads:64] [kernel-poll:true]\n"},
 {memory,[{total,42831280},
          {connection_readers,0},
          {connection_writers,0},
          {connection_channels,0},
          {connection_other,2712},
          {queue_procs,2712},
          {queue_slave_procs,0},
          {plugins,0},
          {other_proc,13403656},
          {mnesia,61024},
          {mgmt_db,0},
          {msg_index,46816},
          {other_ets,761048},
          {binary,13248},
          {code,16907095},
          {atom,654217},
          {other_system,10978752}]},
 {alarms,[]},
 {listeners,[{clustering,25672,"::"},{amqp,5672,"::"}]},
 {vm_memory_high_watermark,0.4},
 {vm_memory_limit,3341025280},
 {disk_free_limit,50000000},
 {disk_free,51512127488},
 {file_descriptors,[{total_limit,65436},
                    {total_used,3},
                    {sockets_limit,58890},
                    {sockets_used,1}]},
 {processes,[{limit,1048576},{used,126}]},
 {run_queue,0},
 {uptime,248}]

</pre>
</p>
<p>Pour les autres distributions, se reporter à la <a href="https://www.rabbitmq.com/download.html">documentation de l'outil</a> (peut nécessiter de compiler Erlang).
</p>
	
      </div>

			<div>
				<h2 id="logstash">Étape 1 : LogStash</h2>
<p>
Dans cette étape, nous allons lire un fichier de logs avec LogStash, découper ces logs pour leur ajouter de la sémantique, et les faire écrire dans la sortie standard. 
</p>
<p>
Pour commencer, nous allons avoir besoin de logs à lire. Pour cela, enregistrer dans <code>$MY_DIR</code> <a href="./files/logstash-tutorial-small.log">ce fichier</a>.
</p>
<p>
Créer ensuite dans <code>$MY_DIR</code> un fichier nommé <code>logstash.conf</code>. L'éditer avec l'éditeur de texte de votre choix, et y placer le code suivant en remplaçant <code>$MY_DIR</code> par sa valeur (par exemple <code>/home/cvillard/elk</code>) :
<pre>
# C'est un commentaire
input {
	# On définit ici les sources de données à traiter
	file {
		path => "$MY_DIR/logstash-tutorial-small.log"
		start_position => beginning 
	}
}

output {
	# on définit ici les destinations pour les données traitées
	stdout {
		# Sortie standard : pas de paramètres
	}
}

</pre>
</p>
<p>
Démarrer LogStash en lui indiquant le fichier de configuration : 
<pre>
$ ./logstash-2.1.0/bin/logstash agent -f './logstash.conf'
Settings: Default filter workers: 2
Logstash startup completed
2015-11-28T15:34:10.995Z claire-i5 83.149.9.216 - - [04/Jan/2015:05:13:42 +0000] "GET /presentations/logstash-monitorama-2013/images/kibana-search.png HTTP/1.1" 200 203023 "http://semicomplete.com/presentations/logstash-monitorama-2013/" "Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36"
</pre>
Vous devriez voir s'afficher dans la console le contenu du fichier, la ligne étant précédée d'un timestamp et du nom de votre PC ajoutés automatiquement par LogStash (<code>2015-11-28T15:34:10.995Z claire-i5</code> dans mon exemple).
</p>
<p>
Interrompre LogStash avec <code>Ctrl+C</code> : 
<pre>
^CSIGINT received. Shutting down the pipeline. {:level=>:warn}
Logstash shutdown completed
</pre>
</p>	

<p>
Nous avons donc lu un fichier avec LogStash et l'avons recopié sur la sortie standard. C'est un bon début, mais ce n'est pas suffisant. Nous allons maintenant modifier la configuration pour découper chaque ligne lue dans le fichier en un message JSON contenant des champs nommés. Cela permettra d'ajouter de la sémantique à chaque ligne, et ensuite de faire des recherches une fois dans ElasticSearch.
</p>

				<div class="alert alert-info" role="alert">
<p>
Pour éviter de relire des lignes déjà lues en cas de redémarrage de LogStash, celui-ci stocke sur le disque l'endroit où il se trouve dans les fichiers qu'il lit. Par défaut, il crée des fichiers <code>.sincedb_*</code> dans le <code>$HOME</code> de l'utilisateur qui le lance. 
</p>
<p>
Ainsi, pour faire relire à LogStash un fichier déjà lu, il faut enlever la ligne contenant l'inode de ce fichier dans le fichier <code>.sincedb_*</code> correspondant (ou supprimer le fichier entier).
</p>
<p>
Il est également possible de paramétrer l'endroit où LogStash écrit ses informations et le nom du fichier correspondant pour éviter de polluer le dossier home et rendre le nom plus explicite que <code>.sincedb_1bd0462c651e913184f7efa9f40f84c6</code> :
<pre>
input {
	# On définit ici les sources de données à traiter
	file {
		path => "$MY_DIR/logstash-tutorial-small.log"
		start_position => beginning 
		# on customise le sincedb_path et le nom du fichier
		sincedb_path => "$MY_DIR/sincedb/sincedb_apache.log"
	}
}
</pre>
</p>
				</div>
<p>
LogStash embarque des patterns pour traiter un grand nombre de formats de logs courants. C'est le cas pour les logs Apache traités ici.
</p>
<p>
Ouvrir le fichier <code>logstash.conf</code> créé précédemment et ajouter le bloc suivant entre le bloc <code>input</code> et le bloc <code>output</code> :
<pre>
filter {
	grok {
		match => { "message" => "%{COMBINEDAPACHELOG}"}
	}
}
</pre>
De plus, on va modifier l'output <code>stdout</code> pour qu'il écrive le message complet en JSON au lieu de le résumer : 
<pre>
output {
	# on définit ici les destinations pour les données traitées
	stdout {
		codec => json
	}
}
</pre>
</p>
<p>
N'oubliez pas de supprimer le fichier <code>.sincedb_*</code> puis redémarrez LogStash avec la même commande que précédemment.
<pre>
$ ./logstash-2.1.0/bin/logstash agent -f './logstash.conf'
Settings: Default filter workers: 2
Logstash startup completed
{"message":"83.149.9.216 - - [04/Jan/2015:05:13:42 +0000] \"GET /presentations/logstash-monitorama-2013/images/kibana-search.png HTTP/1.1\" 200 203023 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"","@version":"1","@timestamp":"2015-11-28T16:10:15.811Z","host":"claire-i5","path":"/home/claire/Documents/atelier_es_mydir/logstash-tutorial-small.log","clientip":"83.149.9.216","ident":"-","auth":"-","timestamp":"04/Jan/2015:05:13:42 +0000","verb":"GET","request":"/presentations/logstash-monitorama-2013/images/kibana-search.png","httpversion":"1.1","response":"200","bytes":"203023","referrer":"\"http://semicomplete.com/presentations/logstash-monitorama-2013/\"","agent":"\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\""}
^CSIGINT received. Shutting down the pipeline. {:level=>:warn}
Logstash shutdown completed
</pre>
</p>
<p>
Une fois mis en forme, on voit que la ligne de log a maintenant la forme suivante :
<pre>
{
	"message":"83.149.9.216 - - [04/Jan/2015:05:13:42 +0000] \"GET /presentations/logstash-monitorama-2013/images/kibana-search.png HTTP/1.1\" 200 203023 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"",
	"@version":"1",
	"@timestamp":"2015-11-28T16:10:15.811Z",
	"host":"claire-i5",
	"path":"/home/claire/Documents/atelier_es_mydir/logstash-tutorial-small.log",
	"clientip":"83.149.9.216",
	"ident":"-",
	"auth":"-",
	"timestamp":"04/Jan/2015:05:13:42 +0000",
	"verb":"GET",
	"request":"/presentations/logstash-monitorama-2013/images/kibana-search.png",
	"httpversion":"1.1",
	"response":"200",
	"bytes":"203023",
	"referrer":"\"http://semicomplete.com/presentations/logstash-monitorama-2013/\"",
	"agent":"\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\""
}
</pre>
Les différentes partie du log d'origine ont été découpées et placées dans des champs nommés. La ligne d'origine est elle conservée en l'état dans le champ <code>message</code>.
</p>

				<div class="alert alert-info" role="alert">
<p>
<strong>Qu'avons-nous fait ?</strong>
</p>
<p>
En ajoutant ce filtre, nous avons utilisé GROK. C'est un outil utilisant une syntaxe pouvant s'apparenter aux expressions régulières, et qui dans LogStash permet de découper un champ (<code>message</code> dans notre cas) en plusieurs champs nommés.
</p>
<p>
Par exemple, le pattern prédéfini que nous avons utilisé est défini par la syntaxe suivante :
<pre>
COMBINEDAPACHELOG %{COMMONAPACHELOG} %{QS:referrer} %{QS:agent}
</pre>
On voit qu'il fait lui-même référence à d'autres patterns : <code>COMMONAPACHELOG</code> et <code>QS</code>. La configuration complète donne : 
<pre>
WORD \b\w+\b
NOTSPACE \S+
BASE10NUM (?&lt;![0-9.+-])(?&gt;[+-]?(?:(?:[0-9]+(?:\.[0-9]+)?)|(?:\.[0-9]+)))
NUMBER (?:%{BASE10NUM})
INT (?:[+-]?(?:[0-9]+))
DATA .*?

MONTHDAY (?:(?:0[1-9])|(?:[12][0-9])|(?:3[01])|[1-9])
MONTH \b(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\b
YEAR (?&gt;\d\d){1,2}

HOUR (?:2[0123]|[01]?[0-9])
MINUTE (?:[0-5][0-9])
# '60' is a leap second in most time standards and thus is valid.
SECOND (?:(?:[0-5][0-9]|60)(?:[:.,][0-9]+)?)
TIME (?!&lt;[0-9])%{HOUR}:%{MINUTE}(?::%{SECOND})(?![0-9])

IPV6 ((([0-9A-Fa-f]{1,4}:){7}([0-9A-Fa-f]{1,4}|:))|(([0-9A-Fa-f]{1,4}:){6}(:[0-9A-Fa-f]{1,4}|((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){5}(((:[0-9A-Fa-f]{1,4}){1,2})|:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3})|:))|(([0-9A-Fa-f]{1,4}:){4}(((:[0-9A-Fa-f]{1,4}){1,3})|((:[0-9A-Fa-f]{1,4})?:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){3}(((:[0-9A-Fa-f]{1,4}){1,4})|((:[0-9A-Fa-f]{1,4}){0,2}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){2}(((:[0-9A-Fa-f]{1,4}){1,5})|((:[0-9A-Fa-f]{1,4}){0,3}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(([0-9A-Fa-f]{1,4}:){1}(((:[0-9A-Fa-f]{1,4}){1,6})|((:[0-9A-Fa-f]{1,4}){0,4}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:))|(:(((:[0-9A-Fa-f]{1,4}){1,7})|((:[0-9A-Fa-f]{1,4}){0,5}:((25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)(\.(25[0-5]|2[0-4]\d|1\d\d|[1-9]?\d)){3}))|:)))(%.+)?
IPV4 (?&lt;![0-9])(?:(?:25[0-5]|2[0-4][0-9]|[0-1]?[0-9]{1,2})[.](?:25[0-5]|2[0-4][0-9]|[0-1]?[0-9]{1,2})[.](?:25[0-5]|2[0-4][0-9]|[0-1]?[0-9]{1,2})[.](?:25[0-5]|2[0-4][0-9]|[0-1]?[0-9]{1,2}))(?![0-9])
IP (?:%{IPV6}|%{IPV4})
HOSTNAME \b(?:[0-9A-Za-z][0-9A-Za-z-]{0,62})(?:\.(?:[0-9A-Za-z][0-9A-Za-z-]{0,62}))*(\.?|\b)

IPORHOST (?:%{HOSTNAME}|%{IP})
USERNAME [a-zA-Z0-9._-]+
USER %{USERNAME}
HTTPDATE %{MONTHDAY}/%{MONTH}/%{YEAR}:%{TIME} %{INT}

COMMONAPACHELOG %{IPORHOST:clientip} %{USER:ident} %{USER:auth} \[%{HTTPDATE:timestamp}\] "(?:%{WORD:verb} %{NOTSPACE:request}(?: HTTP/%{NUMBER:httpversion})?|%{DATA:rawrequest})" %{NUMBER:response} (?:%{NUMBER:bytes}|-)

QUOTEDSTRING (?&gt;(?&lt;!\\)(?&gt;"(?&gt;\\.|[^\\"]+)+"|""|(?&gt;'(?&gt;\\.|[^\\']+)+')|''|(?&gt;`(?&gt;\\.|[^\\`]+)+`)|``))
# QS n'est qu'un alias
QS %{QUOTEDSTRING}

COMBINEDAPACHELOG %{COMMONAPACHELOG} %{QS:referrer} %{QS:agent}
</pre>
On est plutôt contents de ne pas avoir eu à l'écrire nous-même, et on comprend également pourquoi GROK est généralement, dans une configuration LogStash, le plus gros consommateur de temps d'exécution. Les améliorations de performances devront avant tout se porter sur l'optimisation des expressions GROK au cas d'usage.
</p>
<p>
La mise au point d'un pattern GROK "maison" (non embarqué par défaut), pour traiter un format de log non standard, peut donc s'avérer ardue. Pour aider à sa mise au point, il existe un outil en ligne très pratique : <a href="http://grokdebug.herokuapp.com/">Grok Debugger</a>. Il liste également <a href="http://grokdebug.herokuapp.com/patterns">l'ensemble des patterns embarqués dans LogStash</a>.
</p>
				</div>

				<div class="alert alert-warning" role="alert">
<p>
L'extrait de configuration GROK mentionné au dessus contient la ligne suivante pour désigner le mois :
<pre>
MONTH \b(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?)\b
</pre>
On voit que les noms de mois sont en dur, et en anglais. On ne supporte que la version complète et la version abrégée. 
</p>
<p>
De plus, le pattern de date <code>"dd/MMM/YYYY:HH:mm:ss Z"</code> utilisé juste après dans ce tutoriel dépend de la locale de la machine ou de celle précisée en paramètre du filtre <code>date</code>. 
</p>
<p>
C'est pour ces 2 raisons qu'il faut éviter autant que possible les patterns de date contenant du texte pour les jours et les mois, au profit de leur écriture en chiffre qui elle n'est pas dépendante de la locale et n'est pas ambigüe.
</p>
				</div>

<p>
L'ajout de sémantique à notre log a donc plutôt bien fonctionné. Il reste néanmoins une dernière anomalie au niveau du champ <code>@timestamp</code>. En effet, celui-ci est ajouté automatiquement par LogStash, et renseigné avec l'heure du moment où il a lu la ligne dans le fichier. Dans un cas comme ici où on relis des logs anciens, cette date n'a aucun intérêt : la date intéressante est celle contenue dans le log lui-même, soit le 4 janvier 2015 à 05:13:42 dans notre cas, et qui a été placée dans le champ <code>timestamp</code> (sans <code>@</code>) par le pattern GROK <code>COMBINEDAPACHELOG</code>. Nous allons donc utiliser le filtre <code>date</code> pour lire la valeur String du champ <code>timestamp</code> (sans <code>@</code>), la transformer en timestamp et la placer dans le champ <code>@timestamp</code> (avec <code>@</code>) en remplacement de la valeur automatique.
</p>
<p>
Pour cela, ouvrir le fichier <code>logstash.conf</code>, et ajouter un filtre après le GROK :
<pre>
filter {
	grok {
		match => { "message" => "%{COMBINEDAPACHELOG}"}
	}
	date {
		# exemple de date: 04/Jan/2015:05:13:42 +0000
		match => [ "timestamp", "dd/MMM/YYYY:HH:mm:ss Z" ] 
	}
}
</pre>
</p>
<p>
N'oubliez pas de supprimer le fichier <code>.sincedb_*</code> puis redémarrez LogStash avec la même commande que précédemment.
<pre>
$ ./logstash-2.1.0/bin/logstash agent -f './logstash.conf'
Settings: Default filter workers: 2
Logstash startup completed
{"message":"83.149.9.216 - - [04/Jan/2015:05:13:42 +0000] \"GET /presentations/logstash-monitorama-2013/images/kibana-search.png HTTP/1.1\" 200 203023 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"","@version":"1","@timestamp":"2015-01-04T05:13:42.000Z","host":"claire-i5","path":"/home/claire/Documents/atelier_es_mydir/logstash-tutorial-small.log","clientip":"83.149.9.216","ident":"-","auth":"-","timestamp":"04/Jan/2015:05:13:42 +0000","verb":"GET","request":"/presentations/logstash-monitorama-2013/images/kibana-search.png","httpversion":"1.1","response":"200","bytes":"203023","referrer":"\"http://semicomplete.com/presentations/logstash-monitorama-2013/\"","agent":"\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\""}
^CSIGINT received. Shutting down the pipeline. {:level=>:warn}
Logstash shutdown completed
</pre>
</p>
<p>
Si on compare les champs <code>@timestamp</code> et <code>timestamp</code> dans la sortie on a maintenant les valeurs suivantes :
<pre>
	"@timestamp":"2015-01-04T05:13:42.000Z",
	"timestamp":"04/Jan/2015:05:13:42 +0000",
</pre>

Les deux valeurs sont bien identiques, on pourra donc une fois dans ElasticSearch faire une recherche sur le champ standard <code>@timestamp</code> et avoir des résultats pertinents...
</p>
<p>
En cas de soucis, voici <a href="./files/logstash_p1.conf" >le fichier <code>logstash.conf</code></a> obtenu à la fin de cette partie.
</p>

      </div>

			<div>
				<h2 id="es">Étape 2 : ElasticSearch</h2>
<p>
Dans cette étape, nous allons utiliser le résultat de l'étape précédente pour indexer les logs découpés dans ElasticSearch et les rechercher sommairement via l'API REST d'ElasticSearch. Nous apprendrons également comme configurer sommairement ElasticSearch et comment le monitorer via un plugin.
</p>
<p>
Nous allons commencer par envoyer les logs à ElasticSearch depuis LogStash.
</p>
<p>
Pour cela, ouvrir le fichier <code>logstash.conf</code> et modifier le bloc <code>output</code> :
<pre>
output {
    elasticsearch {}
}
</pre>
Comme nous faisons fonctionner LogStash et ElasticSearch sur la même machine et sans sécurité, les paramètres par défaut conviennent. 
</p>
<p>
Supprimer le fichier <code>.sincedb_*</code> et redémarrer Logstash. Une fois la trace <code>Logstash startup completed</code> apparue, on observe du côté d'Elasticsearch 2 nouvelles traces :
<pre>
[2015-12-06 18:25:04,575][INFO ][cluster.metadata         ] [Shirow Ishihara] [logstash-2015.01.04] creating index, cause [auto(bulk api)], templates [logstash], shards [5]/[1], mappings [_default_, logs]
[2015-12-06 18:25:05,342][INFO ][cluster.metadata         ] [Shirow Ishihara] [logstash-2015.01.04] update_mapping [logs]
</pre>
Ces traces indiquent que des logs ont été envoyées à ElasticSearch par Logstash, et qu'ElasticSearch a créé un nouvel index nommé <code>logstash-2015.01.04</code> pour contenir ces données.
</p>
<p>
Nous allons utiliser l'API REST d'ElasticSearch pour consulter les données de ce nouvel index (donc, une seule ligne, ou un seul <em>document</em> selon la terminologie d'ElasticSearch, correspondant à notre log Apache).
</p>
<p>
Entrez dans votre navigateur l'URL suivante : <a href="http://localhost:9200/logstash-2015.01.04/_search" >http://localhost:9200/logstash-2015.01.04/_search</a>. Le résultat devrait être (une fois mis en forme) :
<pre>
{
"took":226,
"timed_out":false,
"_shards":{"total":5,"successful":5,"failed":0},
"hits":{
  "total":1,
  "max_score":1.0,
  "hits":[
    {
      "_index":"logstash-2015.01.04",
      "_type":"logs",
      "_id":"AVF4U1CkEZ3y1kCGmOik",
      "_score":1.0,
      "_source":{
        "message":"83.149.9.216 - - [04/Jan/2015:05:13:42 +0000] \"GET /presentations/logstash-monitorama-2013/images/kibana-search.png HTTP/1.1\" 200 203023 \"http://semicomplete.com/presentations/logstash-monitorama-2013/\" \"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\"",
        "@version":"1",
        "@timestamp":"2015-01-04T05:13:42.000Z",
        "host":"claire-i5",
        "path":"/home/claire/Documents/atelier_es_mydir/logstash-tutorial-small.log",
        "clientip":"83.149.9.216",
        "ident":"-",
        "auth":"-",
        "timestamp":"04/Jan/2015:05:13:42 +0000",
        "verb":"GET",
        "request":"/presentations/logstash-monitorama-2013/images/kibana-search.png",
        "httpversion":"1.1",
        "response":"200",
        "bytes":"203023",
        "referrer":"\"http://semicomplete.com/presentations/logstash-monitorama-2013/\"",
        "agent":"\"Mozilla/5.0 (Macintosh; Intel Mac OS X 10_9_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/32.0.1700.77 Safari/537.36\""
      }
    }
  ]
}
}
</pre>
</p>
<p>
Nous allons détailler un peu ce résultat et en profiter pour expliquer quelques notions du fonctionnement interne d'ElasticSearch.
</p>
<p>
Le début indique que la requête a pris 226ms et qu'elle n'a pas déclenché de timeout :
<pre>
"took":226,
"timed_out":false,
</pre>
</p>
<p>
La suite indique que la requête a été faite sur 5 <em>shards</em> et qu'aucun d'eux n'a déclenché d'erreur.
<pre>
"_shards":{"total":5,"successful":5,"failed":0},
</pre>
Un <em>shard</em> est une portion d'index, qui contient des données. La répartition des données entre les différents index est décidée par l'utilisateur, qui indique dans sa requête le nom de l'index ciblé. LogStash a fait ce travail à notre place en indiquant à ElasticSearch le nom d'index commençant par <code>logstash-</code> et terminant par le jour du log à indexer. 
</p>
<p>
Lorsqu'il reçoit des documents à indexer dans un index donné, ElasticSearch les dispatche de manière homogène entre différents <em>shards</em>. Par défaut, chaque index possède 5 <em>shards</em> mais il est possible de configurer cette valeur en fonction du nombre de nœuds dans le cluster ElasticSearch, de la volumétrie de données et des requêtes réalisées. Chaque <em>shard</em> porte donc une partie des données de l'index, 20% dans notre cas puisque l'index possède 5 <em>shards</em>. Ce sont ces <em>shards</em> qu'ElasticSearch va ensuite automatiquement répartir entre les nœuds du cluster, ainsi que leurs répliques (1 par défaut) pour assurer à la fois la scalabilité, les performances, et la tolérance aux pannes.
</p>
<p>
Enfin, viennent les <em>hits</em>, donc les documents qui correspondaient à la recherche effectuée. Dans notre cas, nous n'avons précisé aucun critère donc la totalité des documents (1) a été retournée.
</p>
<p>
On retrouve ainsi le nombre total de résultats (1), et le <code>max_score</code> qui indique à quel point le document considéré comme le plus pertinent par rapport à la recherche, est pertinent.
<pre>
"total":1,
"max_score":1.0,
</pre>
Le fonctionnement du scoring est assez complexe, nous n'allons donc pas nous attarder dessus dans ce tutoriel. Il faut cependant savoir que c'est le critère de tri par défaut des résultats (du plus pertinent au moins pertinent). Cela étant assez peu intéressant pour consulter des logs (que nous préférons généralement triés par date, même quand nous cherchons une chaîne de caractères précise par exemple), nous préciserons donc souvent un autre critère de tri, notamment sur le champ <code>@timestamp</code> vu précédemment.
</p>
<p>
Viennent ensuite les résultats eux-même. Dans notre exemple, nous retrouvons bien la ligne de log découpée en champs nommés vue à l'étape 1. Un <em>hit</em> contient, en plus du contenu du document (la ligne de log) stocké dans le champ <code>_source</code>, d'autres champs correspondant à des metadata ajoutées ou calculées par ElasticSearch. 
<pre>
"_index":"logstash-2015.01.04",
"_type":"logs",
"_id":"AVF4U1CkEZ3y1kCGmOik",
"_score":1.0,
</pre>
On y retrouve le nom de l'index dans le champ <code>_index</code>, et le score par rapport à la recherche dans <code>_score</code>. Le champ <code>_id</code> contient quant à lui l'identifiant unique du document dans l'index, ce qui permet d'y accéder ensuite directement. Il peut être imposé par le client lors de l'envoi des documents à indexer, ou plus fréquemment il n'est pas précisé et comme ici ElasticSearch le génère.
</p>
<p>
Enfin, on trouve le champ <code>_type</code>, positionné à la valeur <code>logs</code>. Ici encore, LogStash nous a mâché le travail et à indiqué à ElasticSearch que le document qu'il lui envoyait était de type <code>logs</code>. Cela a une grande importance, car c'est sur ce type qu'ElasticSearch va se baser pour savoir quels champs il peut s'attendre à trouver dans le document, et comment il va devoir les indexer : chaînes de caractères ? entiers ? date ? indexés en texte brut ou découpés selon des caractères de séparation ? etc.
</p>
<p>
Si on relit de nouveau les traces produites par ElasticSearch lors de la réception du log, on voit que la seconde mentionne ce type <code>logs</code> :
<pre>
[2015-12-06 18:25:05,342][INFO ][cluster.metadata         ] [Shirow Ishihara] [logstash-2015.01.04] update_mapping [logs]
</pre>
En effet, comme nous n'avons pas indiqué à ElasticSearch comment interpréter le type <code>logs</code>, il a dû deviner, et a stocké le résultat de sa tentative dans un <em>mapping</em>.
</p>
<p>
Comme cela a une grande importance sur la qualité et l'efficacité des recherches faites sur les différents champs (on peut indiquer une plage de dates en critère de recherche, cela ne fonctionnera pas si le champ est une simple chaîne de caractères), il est intéressant de voir comment ElasticSearch a deviné. Pour cela, entrer l'URL suivante dans votre navigateur : <a href="http://localhost:9200/logstash-2015.01.04/_mapping/logs/">http://localhost:9200/logstash-2015.01.04/_mapping/logs/</a>.
</p>
<p>
Le résultat est assez verbeux, nous allons donc nous intéresser à certains champs, et notamment ceux qui ne sont pas de simples chaînes de caractères.
</p>
<p>
Tout d'abord, le champ <code>@timestamp</code> : <a href="http://localhost:9200/logstash-2015.01.04/_mapping/logs/field/@timestamp">http://localhost:9200/logstash-2015.01.04/_mapping/logs/field/@timestamp</a>
<pre>
{
  "logstash-2015.01.04":{
    "mappings":{
      "logs":{
        "@timestamp":{
          "full_name":"@timestamp",
          "mapping":{
            "@timestamp":{
              "type":"date",
              "format":"strict_date_optional_time||epoch_millis"
            }
          }
        }
      }
    }
  }
}
</pre>
Ce champ est standard dans LogStash, ElasticSearch l'a reconnu et lui a donc appliqué de lui même le type <code>date</code> avec au choix les 2 formats <code>strict_date_optional_time</code> et <code>epoch_millis</code> (les formats par défaut sont <a href="https://www.elastic.co/guide/en/elasticsearch/reference/current/mapping-date-format.html#built-in-date-formats">ici</a>, sinon il est possible d'indiquer son propre format selon la syntaxe de la librairie JodaTime).
</p>
<p>
Prenons maintenant le champ <code>bytes</code> : <a href="http://localhost:9200/logstash-2015.01.04/_mapping/logs/field/bytes">http://localhost:9200/logstash-2015.01.04/_mapping/logs/field/bytes</a>
<pre>
{
  "logstash-2015.01.04":{
    "mappings":{
      "logs":{
        "bytes":{
          "full_name":"bytes",
          "mapping":{
            "bytes":{
              "type":"string",
              "norms":{
                "enabled":false
              },
              "fielddata":{
                "format":"disabled"
              },
              "fields":{
                "raw":{
                  "type":"string",
                  "index":"not_analyzed",
                  "ignore_above":256
                }
              }
            }
          }
        }
      }
    }
  }
}
</pre>
Il a été détecté comme une chaîne de caractères (<code>"type":"string"</code>), alors que nous savons que c'est un nombre entier. En l'état, nous ne pourrons pas faire de recherche sur les documents où le champ <code>bytes</code> est supérieur à 200 000 par exemple.
</p>
<p>
Si on observe le mapping complet, on trouve d'autres champs dont Elasticsearch a mal deviné le type :
<ul>
<li><code>timestamp</code> (<code>string</code> au lieu d'une date à un format particulier)</li>
<li><code>response</code> (<code>string</code> au lieu d'un entier)</li>
</ul>
</p>
<p>
Il n'est pas possible de corriger un mapping Elasticsearch sans ré-indexer les données. Comme dans notre cas nous n'avons qu'une seule donnée, nous allons supprimer l'index, et le document et le mapping deviné avec lui, pour pouvoir le reconfigurer proprement et soumettre de nouveau notre ligne de log pour indexation.
</p>
<p>
Deux solutions existent pour supprimer un index. La première est la ligne de commande si on dispose du programme cURL installé :
<pre>
$ curl -XDELETE "http://localhost:9200/logstash-2015.01.04/"
{"acknowledged":true}
</pre>
La seconde est l'installation d'un plugin de monitoring standard d'ElasticSearch, très utile pour consulter rapidement la santé de son cluster, le nombre et le contenu des index ainsi que tout le paramétrage du cluster ou des nœuds : <strong>Head</strong>.
</p>
<p>
Head est un plugin communautaire hébergé sur <a href="https://mobz.github.io/elasticsearch-head/">GitHub</a> mais reconnu par ElasticSearch. L'installation est très simple depuis Internet :
<pre>
$ ./elasticsearch-2.1.0/bin/plugin  install mobz/elasticsearch-head
-> Installing mobz/elasticsearch-head...
Trying https://github.com/mobz/elasticsearch-head/archive/master.zip ...
Downloading ..............................................DONE
Verifying https://github.com/mobz/elasticsearch-head/archive/master.zip checksums if available ...
NOTE: Unable to verify checksum for downloaded plugin (unable to find .sha1 or .md5 file to verify)
Installed head into /home/claire/Documents/atelier_es_mydir/elasticsearch-2.1.0/plugins/head
</pre>
Une fois installé, accédez à l'URL suivante : <a href="http://localhost:9200/_plugin/head/">http://localhost:9200/_plugin/head/</a>
<img src="images/es_head.png" />
</p>
<p>
On trouve sur le premier onglet les index (<code>.kibana</code>, qui n'existe que si vous avez déjà lancé Kibana, et notre index <code>logstash-2015.01.04</code>) et la répartition des shards (les boites vertes numérotées) entre les nœuds du cluster (un seul pour nous, nommé <code>Shirow Ishihara</code> sur la capture). Comme par défaut ElasticSearch essaye de répliquer les données une fois sur un second nœud qui n'existe pas dans notre configuration, ils apparaissent <code>Unassigned</code>, non assignés. Cela explique la santé du cluster qui vaut <code>yellow</code> (une partie des répliques est non assignée). Elle serait <code>green</code> si toutes les répliques étaient assignées à des nœuds, et <code>red</code> si certaines données primaires étaient en cours de récupération (après un redémarrage de notre unique nœud par exemple).
</p>
<p>
Le second onglet "Index" permet de lister les index.
</p>
<p>
L'onglet "Navigateur" permet de consulter les données en choisissant des critères de filtres dans la colonne gauche.
</p>
<p>
Les onglets "Recherche structurée" et "Autres requêtes" permettent de faire des requêtes complexes sur le cluster.
</p>
<p>
Maintenant que nous avons installé Head, nous allons pouvoir nous en servir pour supprimer notre index mal configuré. Pour cela, revenir sur l'onglet "Aperçu". Cliquer sur le bouton "Action" sous le nom de l'index <code>logstash-2015.01.04</code> et choisir "Effacer...".
</p>
<p>
<img src="images/es_effacer.png" />
</p>
<p>
Entrer le texte "SUPPRIMER" dans la pop-up puis cliquer sur OK pour confirmer. Une nouvelle pop-up devrait indiquer <code>{"acknowledged":true}</code> quasiment instantanément, et l'index disparaître de l'écran après avoir cliqué sur OK.
</p>
<p>
Nous pouvons maintenant indiquer à ElasticSearch comment interpréter les futures données de type <code>logs</code> que nous allons lui envoyer. Pour cela, nous allons rédiger un <em>template</em>. C'est un élément de configuration qui contient, pour un type donné, quels champs il contient et comment les interpréter. Ce <em>template</em> sera automatiquement transformé en <em>mapping</em> lors de la création d'un index dont le nom correspondra au champ d'action du <em>template</em>.
</p>
<p>
Pour faire cela, le programme cURL est le plus pratique. Taper la commande suivante (attention aux sauts de lignes intempestifs !) :
<pre>
curl -XPUT "http://localhost:9200/_template/logs_template" -d '
{
  "template" : "logstash-*",
  "mappings" : {
    "logs" : {
      "properties" : {
        "bytes" : { "type" : "integer" },
        "response" : { "type" : "integer" },
        "timestamp" : { "type" : "date", "format" : "dd/MMM/YYYY:HH:mm:ss Z" }
      }
    }
  }
}'
{"acknowledged":true}
</pre>
</p>
				<div class="alert alert-info" role="alert">
					Pour simplifier, nous ne définissons que les 3 champs qui posaient problème. Pour fiabiliser au maximum l'indexation, il est préférable dans un cas réel de définir l'ensemble des champs pour éviter qu'une valeur "bizarre" ne vienne perturber la configuration automatique des types et empêcher de futures indexations.
				</div>
<p>
Ensuite, supprimer le fichier <code>.sincedb_*</code> et redémarrer LogStash. Rafraîchir la page de Head jusqu'à voir apparaître l'index avec le même nom que précédemment.
</p>
<p>
Vérifier le type du champ <code>bytes</code> avec l'URL suivante : <a href="http://localhost:9200/logstash-2015.01.04/_mapping/logs/field/bytes">http://localhost:9200/logstash-2015.01.04/_mapping/logs/field/bytes</a>. On voit qu'il est bien considéré comme un entier, nous pourrons donc faire des requêtes avec des comparaisons de nombres dessus.
<pre>
{
  "logstash-2015.01.04":{
    "mappings":{
      "logs":{
        "bytes":{
          "full_name":"bytes",
          "mapping":{
            "bytes":{"type":"integer"}
          }
        }
      }
    }
  }
}
</pre>
</p>
<p>
Nous avons vu comment paramétrer l'indexation d'ElasticSearch, et comment gérer son contenu via Head. Pour préparer l'étape suivante avec Kibana, nous allons maintenant lui faire indexer une volumétrie plus importante de données.
</p>
<p>
Pour cela, enregistrer le <a href="./files/logstash-tutorial-dataset.log">fichier suivant</a> sur votre disque.
</p>
<p>
Ouvrir le fichier <code>logstash.conf</code> et modifier le début pour lire le nouveau fichier au lieu de l'ancien.
<pre>
input {
  # On définit ici les sources de données à traiter
  file {
    path => "$MY_DIR/logstash-tutorial-dataset.log"
    start_position => beginning
    # on customise le sincedb_path et le nom du fichier
    sincedb_path => "$MY_DIR/sincedb/sincedb_apache.log"
  }
}
</pre>
</p>
<p>
Supprimer l'index dans ElasticSearch via Head ou cURL, supprimer le fichier <code>.sincedb_*</code> et redémarrer LogStash. Rafraîchir la page de Head jusqu'à voir réapparaître l'index. Il doit contenir maintenant 100 documents et non plus 1 seul.
</p>
<p>
<img src="images/es_100.png" />
</p>
      </div>

			<div>
				<h2 id="kibana">Étape 3 : Kibana</h2>
<p>
Dans cette étape, nous allons voir comment Kibana permet de rechercher facilement dans ElasticSearch, et nous créerons un dashboard.
</p>
<p>
Si Kibana est arrêté, lancez le avec la commande :
<pre>
$ ./kibana-4.3.0-linux-x64/bin/kibana
</pre>
Une fois la trace suivante obtenue dans la console :
<pre>
  log   [14:11:46.405] [info][listening] Server running at http://0.0.0.0:5601
</pre>

Vérifier que Kibana répond à l'URL <a href="http://localhost:5601/">http://localhost:5601/</a>.
</p>
<p>
Au premier lancement de Kibana, il nous demande quelques éléments de configuration de manière à savoir quelles données contenues dans ElasticSearch il va devoir traiter.
</p>
				<div class="alert alert-warning" role="alert">Attention si votre cluster ElasticSearch contient un grand nombre de templates utilisés dans tous vos index (plus de 50 templates et plus de 40 index par exemple) et que sur vos nœuds la Heap disponible pour ElasticSearch est plutôt faible : l'affichage de cet écran déclenche un parsing dans Elasticsearch de tous les mappings de tous les index. Cette requête peut utiliser jusqu'à 2Go de mémoire dans ElasticSearch avec ~2000 mappings, et provoquer la mort du cluster si la mémoire disponible est insuffisante ! Cette anomalie est en cours de correction côté ElasticSearch comme côté Kibana...</div>
      </div>
<p>
Nous souhaitons traiter des données basées sur le temps (<em>time-based events</em>), situés dans des index (un seul index en fait) dont le nom commence par <code>logstash-*</code> et dont le champ normalisé contenant le timestamp est <code>@timestamp</code> (rappelez vous précédemment, nous avions configuré tout le nécessaire dans Logstash pour que ce champ soit correctement positionné).
</p>
<p>
L'écran de configuration doit donc être rempli de la manière suivante :
<img src="./images/kibana_settings.png" />
Cliquez ensuite sur <code>Create</code>.
</p>
<p>
Un second écran nous affiche la configuration dans ElasticSearch de tous les champs connus dans les index correspondant au pattern <code>logstash-*</code> configuré précédemment. Il est possible de changer l'affichage des champs dans les dashboards pour une meilleure lisibilité en cliquant sur le petit icône en forme de stylo en face de chaque ligne. Nous allons pour notre part garder la configuration par défaut des champs.
</p>
<p>
Outre la configuration des index à scruter que nous avons déjà ajustée, Kibana offre de nombreuses options de configuration via les écrans de Settings. L'avertissement sur la page Advanced est clair : <em>Caution: You can break stuff here</em>. Nous allons donc conserver les paramètres par défaut.
</p>
<p>
Nous pouvons maintenant cliquer sur le menu <code>Discover</code> pour commencer à parcourir nos données. Pour l'instant, il ne trouve aucun résultat car par défaut il cherche des données datées des dernières 15 minutes et nos données de test datent du 04 janvier 2015.
</p>
<p>
Pour changer cela et voir nos données, cliquer sur l'icône en forme de pendule en haut à droite de l'écran, sur le menu <code>Absolute</code> en choisir en date de début <code>2015-01-04 06:00:00.000</code> et en date de fin <code>2015-01-04 07:00:00.000</code>.
</p>
<p>
<img src="./images/kibana_time_picker.png" />
</p>
<p>
Cliquer sur <code>Go</code>.
</p>
<p>
Cette fois, nous avons enfin des données ! Kibana nous affiche par défaut, la répartition des valeurs de <code>@timestamp</code> par minute sur la plage de dates sélectionnée. Cela peut déjà être très utile pour monitorer l'activité d'un site Web, puisque nos données de test sont des logs Apache.
</p>
<p>
La barre de recherche en haut de l'écran contient par défaut le texte <code>*</code>, qui signifie "tous les documents".
</p>
<p>
Pour affiner cette recherche, il est possible de rechercher un mot ou un ensemble de mots. Par exemple, entrez <code>*.html</code> et validez pour ne voir que les logs faisant référence à l'accès à des ressources HTML.
</p>
<p>
Vous pouvez tester d'autres recherches, sur les codes retour ou le contenu des URL par exemple.
</p>
<p>
Nous voulons maintenant rechercher tous les logs venant d'un client dont l'IP commence par <code>86.1</code>. Entrez donc <code>86.1</code> dans le champ de recherche et validez : Aucun résultat ?! 
</p>
<p>
Essayons alors de préciser le champ sur lequel nous voulons rechercher. Il s'agit du champ <code>clientip</code>. Entrez donc <code>clientip:86.1</code> et validez... Pas mieux :(
</p>
<p>
C'est en fait ici que les paramètres d'indexation définis dans le template Elasticsearch à l'étape précédente entrent en jeu. Nous n'avons pas configuré explicitement ce champ, ElasticSearch a donc fait des déductions pour déterminer son format et la manière de l'indexer. Si nous demandons cette configuration à ElasticSearch via l'URL <a href="http://localhost:9200/logstash-2015.01.04/_mapping/logs/field/clientip" >http://localhost:9200/logstash-2015.01.04/_mapping/logs/field/clientip</a> nous avons le résultat suivant :
<pre>
{
  "logstash-2015.01.04": {
    "mappings":{
      "logs":{
        "clientip":{
          "full_name":"clientip",
          "mapping":{
            "clientip":{
              "type":"string",
              "norms":{
                "enabled":false
              },
              "fielddata":{
                "format":"disabled"
              },
              "fields":{
                "raw":{
                  "type":"string",
                  "index":"not_analyzed",
                  "ignore_above":256
                }
              }
            }
          }
        }
      }
    }
  }
}
</pre>
Les parties qui nous intéressent sont : <code>"type":"string"</code> et <code>"index":"not_analyzed"</code>. Le champ est une chaîne de caractères et n'est pas analysé lors de l'indexation. Cela signifie qu'ElasticSearch va indexer la valeur exacte du champ, et lors de la recherche, si on ne lui précise pas que l'on recherche une partie seulement de cette valeur, il va chercher la valeur exacte. Ce qui explique que nous n'ayons aucun résultat avec notre recherche <code>clientip:86.1</code>.
</p>
<p>
Nous allons donc indiquer à ElasticSearch que la chaîne entrée doit correspondre au début de la valeur du champ, mais que le champ peut contenir d'autres caractères à la suite. Pour cela, nous ajoute une étoile à la fin : <code>clientip:86.1*</code>. Nous obtenons maintenant bien 3 résultats, correspondant à 3 requêtes faites depuis l'IP 86.1.76.62.
</p>
<p>
Dans la colonne à gauche de l'écran, Kibana affiche tous les champs disponible dans les données retournées par la recherche, ainsi qu'une répartition des valeurs de chaque champ. Ainsi, si on clique sur le champ <code>response</code>, on voit que 98% des requêtes ont retourné un code 200, 1% un code 404 et 1% un code 304...
</p>
<img src="./images/kibana_fields_facets.png" />
<p>
L'affichage du tableau des résultats est pour l'instant un peu brut : il affiche uniquement le timestamp et le contenu brut du document tel que stocké dans ElasticSearch. Ce n'est pas très lisible, nous allons donc configurer Kibana pour afficher les informations les plus intéressantes.
</p>
<p>
Pour cela, dans la colonne à gauche de l'écran pointer la souris sans cliquer sur le champ <code>response</code> et cliquer sur le petit bouton <code>add</code> qui s'affiche. Répéter l'opération avec les champs <code>clientip</code> et <code>request</code>. Le tableau est déjà bien plus lisible !
</p>
<p>
A vous maintenant de sélectionner d'autres champs, d'en supprimer, de changer l'ordre des colonnes dans le tableau puis de trier le tableau selon l'une ou l'autre des colonnes. Essayez aussi de cliquer sur certaines zones du graphique pour voir leur effet...
</p>
<img src="./images/kibana_discover_final.png" />
<p>
Passons maintenant à l'onglet <code>Visualize</code>. Cet onglet permet de créer des graphiques à partir des données retournées par la recherche. Par exemple, nous pouvons reproduire le graphique du nombre de documents par minute vu sur la page précédente.
</p>
<p>
Pour cela, configurer les options de graphique dans la colonne de gauche comme sur la capture d'écran ci-dessous et cliquer sur la flèche verte en haut pour afficher le graphique :
</p>
<img src="./images/kibana_visualize.png" />
<p>
De nombreuses autres visualisations sont disponible, outre l'affichage en histogramme que nous avons vu. Pour les découvrir, cliquer sur l'icône <img src="./images/kibana_new_viz.png" /> à côté de la barre de recherche. Les autres icônes permettent également de sauvegarder une visualisation, d'en charger une sauvegardée précédemment et de les partager.
</p>
<p>
N'oubliez pas de sauvegarder 2 ou 3 visualisations pour pouvoir les utiliser dans la suite du tutoriel...
</p>
<p>
Enfin, l'onglet <code>Dashboard</code> permet de configurer des tableaux de bords et de les sauvegarder.
</p>
<p>
Créez un nouveau Dashboard comme indiqué en choisissant différentes recherches et visualisations enregistrées précédemment, et observez comme il évolue en fonction des recherches que vous faites. 
</p>
				<div class="alert alert-warning" role="alert">
<p>Les visualisations, et a fortiori les dashboards, utilisent une fonctionnalité d'ElasticSearch nommé Agrégations. Cela permet de réaliser en une seule requête, et en profitant des performances et de la distribution des recherches, d'obtenir à la fois les documents correspondant à la recherche et un certain nombre de valeurs calculées à partir du contenu de ces documents : nombre d'occurrence de chaque valeur différente, répartition des valeurs dans le temps, etc.
</p>
<p>
Cette fonctionnalité est très efficace et très pratique dans de nombreux cas, mais elle implique par contre une charge CPU importante sur le cluster ainsi que la mise en mémoire de nombreuses données. Si ce second point a été largement amélioré dans la version 2.*, la charge CPU reste importante et l'exécution simultanée par plusieurs utilisateurs d'agrégations complexes sur une grande volumétrie de documents (plusieurs centaines de milliers) peut ralentir globalement le cluster. 
</p>
</div>
  
				<div class="alert alert-success" role="alert">Vous voilà arrivés à la fin du tutoriel. Vous pouvez continuer à lire pour aller plus loin...</div>

				<h2 id="further">Pour aller plus loin...</h2>
Nous avons vu une infrastructure simple d'exploitation de logs. Elle souffre de nombreux points faibles : goulets d'étranglements de performances, vulnérabilité aux pannes, impact sur la charge des machines monitorées... Ces points peuvent être résolus par l'ajout de nouvelles briques et l'utilisation de clusters.

				<h3 id="rspec">Tests unitaires de LogStash</h3>
<p>
L'écriture d'une configuration LogStash peut être très complexe : patterns GROK, utilisation de conditions sur des champs pour appliquer des opérations particulières, transformations de valeurs de champs... 
</p>
<p>
Pour fiabiliser cela, LogStash fourni un outil de tests unitaires, qui permet de contrôler qu'une entrée a bien été transformée comme prévu...
</p>

				<div class="alert alert-danger" role="alert">
					TODO
				</div>

				
				<h3 id="broker">Utilisation d'un agent et d'un broker de messages</h3>

<p>Deux problèmes principaux sont présents dans l'architecture telle que mise en place dans ce tutoriel : le traitement des messages avec Grok peut être très gourmand en CPU, et le fait de pousser directement dans ElasticSearch implique un couplage fort entre les deux briques. 
</p>
<p>Ces deux points peuvent être problématiques en production : La charge induite par LogStash peut perturber les applications supervisées, et toute indisponibilité d'ElasticSearch peut impacter le fonctionnement de l'agent.
</p>
<p>Pour résoudre cela, il est préférable d'installer LogStash sur les machines supervisées avec une configuration minimale, qui ne fait que lire les fichiers de logs, gérer le multi-ligne si nécessaire, et pousser les messages dans la suite de l'infrastructure, elle située sur des machines dédiées. Le traitement poussé des messages (Grok notamment) sera réalisé par une ou plusieurs autres instances de LogStash (voir le paragraphe "Clustering" plus loin) sur ces machines dédiées, et se chargera de pousser dans ElasticSearch.
</p>
<p>
Pour communiquer entre le LogStash "agent" installé sur les machines clientes et le LogStash "serveur" réalisant les traitements, il faut insérer entre eux deux une brique intermédiaire de "broker de messages". Plusieurs technologies peuvent être utilisées pour cela : Redis, RabbitMQ, Apache Kafka... Chacune de ces solutions ont leurs avantages et leurs inconvénients, à adapter à chaque cas d'usage. RabbitMQ offrant une bonne simplicité de mise en œuvre et une interface d'administration pratiques dans le cadre de ce tutoriel, c'est ce que nous allons utiliser.
</p>
<div class="alert alert-info" role="alert">Dans le cadre de ce tutoriel, il est possible de démarrer 2 fois LogStash sur votre PC en même temps, en précisant 2 fichiers de configuration différents pour la partie "agent" et la partie "serveur".
</div>
<div class="alert alert-info" role="alert">Voici un extrait de la documentation de RabbitMQ sur les concepts spécifiques à RabbitMQ d'exchange, de queue et de routage dans RabbitMQ : 
				<div class="alert alert-danger" role="alert">
					TODO
				</div>
</div>

<p>
Dans cette partie, vous pouvez donc :
<ol>
<li>Démarrer un serveur RabbitMQ sur votre poste via la commande <code>$MY_DIR/rabbitmq_server-3.5.6/sbin/rabbitmq-server -detached</code> 
</li>
<li>Configurer un exchange, une queue et un routage dans RabbitMQ (voir plus haut l'explication de ces concepts) :
				<div class="alert alert-danger" role="alert">
					TODO
				</div>
</li>
<li>Séparer le fichier <code>logstash.conf</code> en 2 parties. La première jouera le rôle de l'agent, et contiendra la lecture du fichier de logs et la dépose dans RabbitMQ. La seconde jouera le rôle du serveur, et lira les messages depuis RabbitMQ et les déposer dans ElasticSearch comme précédemment.
</li>
<li>Démarrer les 2 instances de LogStash.
</li>
<li>Constater sur les logs arrivent dans ElasticSearch tout comme avant.
</li>
</ol>

L'état de RabbitMQ et des queues qu'il contient peut être consulté sur l'IHM d'administration (notez le <code>s</code> à <code>https</code>) : <a href="https://localhost:15671/">https://localhost:15671/</a>

</p>


				<h3 id="cluster">Clustering</h3>
<p>
Telle qu'elle, l'application n'est pas tolérante aux pannes : si ElasticSearch s'arrête, toute la chaîne devient indisponible. Pour un usage en production, la haute disponibilité, la tolérance aux pannes et la montée en charge par du scaling horizontal peuvent être nécessaires.
</p>
<p>
Comme nous l'avons vu, il est très facile de démarrer plusieurs instances de LogStash. Ainsi, il serait très facile d'installer LogStash sur 2 ou plus de machines, avec un fichier de configuration identique leur faisant lire la même file RabbitMQ et déposer dans le même ElasticSearch, pour dupliquer cette partie de l'infrastructure.
</p>
<p>
Réaliser la même chose au niveau d'ElasticSearch n'est guère plus complexe : il suffit de démarrer un second nœud avec le même nom de cluster que le premier et d'indiquer le premier nœud dans la liste des nœuds du cluster pour que le cluster se forme. En gardant la configuration par défaut qui crée 1 réplique de toutes les données et la répartition automatique des données entre les nœuds implémentée dans ElasticSearch, la haute disponibilité est à l'œuvre...
</p>
<p>
Dans cette partie, vous pouvez donc :
<ol>
<li>Dupliquer le fichier de configuration <code>elasticsearch.yml</code>, et modifier les ports d'écoute pour pouvoir le lancer sur la même machine que le premier nœud.
<div class="alert alert-danger" role="alert">
					TODO
				</div>
</li>
<li>Configurer dans ce même fichier le premier nœud comme autre membre du cluster pour qu'ils se découvrent :
				<div class="alert alert-danger" role="alert">
					TODO
				</div>
</li>
<li>Démarrer ce second nœud avec le nouveau fichier de configuration, et observer le résultat dans l'IHM Head d'ElasticSearch, sur le premier ou le second nœud (les mêmes données sont affichées) : <a href="https://localhost:9200/">https://localhost:9200/</a>
</li>
</ol>
</p>

<div class="alert alert-info" role="alert">Pour éviter les points uniques de défaillance (SPOF, Single Point of Failure) si à l'étape précédente on a mis en place RabbitMQ entre un LogStash agent et un serveur, il faudra également le mettre en cluster. Cela sort du cadre de ce Hands on, mais toute la documentation est disponible <a href="https://www.rabbitmq.com/clustering.html">sur le site du produit</a>.
</div>

<div class="alert alert-success" role="alert">Vous voilà à la toute fin du tutoriel cette fois-ci... Have fun avec ELK ;)</div>

      </div>

    </div><!-- /.container -->

		<footer class="footer" role="contentinfo">
      <div class="container">
        <ul class="footer-links text-center">
					<li><a href="http://www.duchess-france.org/"><img src="images/duchess.jpg" heigth="32px" width="32px" /></a></li>
      		<li>&middot;</li>
					<li><a href="https://twitter.com/leneurone_eu"><img src="images/twitter.png" /></a></li>
      		<li>&middot;</li>
					<li><a href="https://github.com/leneurone/atelier-duchess-elk"><img src="images/github.png" /></a></li>
				</ul>
      </div>
    </footer> <!-- footer -->


    <!-- Bootstrap core JavaScript
    ================================================== -->
    <!-- Placed at the end of the document so the pages load faster -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/1.11.3/jquery.min.js"></script>
    <script src="../../dist/js/bootstrap.min.js"></script>
    <!-- IE10 viewport hack for Surface/desktop Windows 8 bug -->
    <script src="../../assets/js/ie10-viewport-bug-workaround.js"></script>
  </body>
</html>
